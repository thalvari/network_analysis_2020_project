{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "papermill": {
     "duration": 0.009009,
     "end_time": "2020-02-27T10:09:27.028795",
     "exception": false,
     "start_time": "2020-02-27T10:09:27.019786",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "# Clustering IMDB movie actors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "papermill": {
     "duration": 0.009008,
     "end_time": "2020-02-27T10:09:27.045810",
     "exception": false,
     "start_time": "2020-02-27T10:09:27.036802",
     "status": "completed"
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "Defining notebook params:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "papermill": {
     "duration": 0.013013,
     "end_time": "2020-02-27T10:09:27.066830",
     "exception": false,
     "start_time": "2020-02-27T10:09:27.053817",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "seed = 42\n",
    "n_processes = 12\n",
    "\n",
    "n_spectral_components = 200\n",
    "\n",
    "# n_clusters = 23\n",
    "min_cluster_size = 150\n",
    "min_samples = 10\n",
    "\n",
    "pdf_postfix = \"_custom_200\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "papermill": {
     "duration": 0.008008,
     "end_time": "2020-02-27T10:09:27.083845",
     "exception": false,
     "start_time": "2020-02-27T10:09:27.075837",
     "status": "completed"
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "Import stuff and ignore warnings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "papermill": {
     "duration": 1.921748,
     "end_time": "2020-02-27T10:09:29.014601",
     "exception": false,
     "start_time": "2020-02-27T10:09:27.092853",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set_style(\"white\")\n",
    "from IPython.core.display import display, HTML\n",
    "from collections import Counter\n",
    "from hdbscan import HDBSCAN\n",
    "from matplotlib.axes._axes import _log\n",
    "_log.setLevel(\"ERROR\")\n",
    "from matplotlib.patches import Patch\n",
    "from networkx.algorithms.community import girvan_newman\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn.manifold import spectral_embedding\n",
    "from sklearn.metrics import adjusted_mutual_info_score, adjusted_rand_score, fowlkes_mallows_score, silhouette_score,\\\n",
    "    v_measure_score\n",
    "from sklearn.utils.graph_shortest_path import graph_shortest_path\n",
    "from umap import UMAP\n",
    "\n",
    "from parallel_betweenness import betweenness_centrality_parallel\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "papermill": {
     "duration": 0.008007,
     "end_time": "2020-02-27T10:09:29.031616",
     "exception": false,
     "start_time": "2020-02-27T10:09:29.023609",
     "status": "completed"
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "Loading the network and taking the largest connected component:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "papermill": {
     "duration": 385.238372,
     "end_time": "2020-02-27T10:15:54.278996",
     "exception": false,
     "start_time": "2020-02-27T10:09:29.040624",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nodes: 13406\n",
      "edges: 390859\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(seed)\n",
    "\n",
    "with open(\"data/edges.pkl\", \"rb\") as f:\n",
    "    G = nx.Graph()\n",
    "    G.add_edges_from(pickle.load(f))\n",
    "G.remove_nodes_from(set(nx.nodes(G)) - max(nx.connected_components(G), key=len))\n",
    "\n",
    "adj_matrix = nx.to_numpy_array(G)\n",
    "betweenness = betweenness_centrality_parallel(G, processes=n_processes)\n",
    "node_list = list(G.nodes())\n",
    "\n",
    "print(f\"nodes: {len(node_list)}\")\n",
    "print(f\"edges: {len(G.edges())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "papermill": {
     "duration": 0.009008,
     "end_time": "2020-02-27T10:15:54.297012",
     "exception": false,
     "start_time": "2020-02-27T10:15:54.288004",
     "status": "completed"
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "Using Spectral Embedding, reducing dimensions with UMAP and clustering with HDBSCAN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "papermill": {
     "duration": 79.059107,
     "end_time": "2020-02-27T10:17:13.365127",
     "exception": false,
     "start_time": "2020-02-27T10:15:54.306020",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.random.seed(seed)\n",
    "random_state = np.random.RandomState(seed)\n",
    "\n",
    "embedding = spectral_embedding(\n",
    "    adj_matrix, n_components=n_spectral_components, drop_first=False, random_state=random_state\n",
    ")\n",
    "embedding = UMAP(\n",
    "    n_components=2, n_neighbors=30, min_dist=0.0, random_state=random_state\n",
    ").fit_transform(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "papermill": {
     "duration": 0.233221,
     "end_time": "2020-02-27T10:17:13.609340",
     "exception": false,
     "start_time": "2020-02-27T10:17:13.376119",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clusters: 27\n",
      "cluster sizes: [(22, 1758), (20, 1641), (8, 801), (7, 791), (11, 779), (-1, 743), (6, 727), (4, 613), (18, 534), (19, 383), (25, 372), (12, 364), (26, 352), (23, 338), (16, 304), (17, 288), (21, 279), (10, 278), (24, 275), (14, 260), (3, 255), (2, 254), (5, 198), (1, 177), (13, 171), (15, 168), (9, 153), (0, 150)]\n",
      "noise level: 0.055\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(seed)\n",
    "random_state = np.random.RandomState(seed)\n",
    "\n",
    "clusters = HDBSCAN(\n",
    "    min_samples=min_samples, min_cluster_size=min_cluster_size, core_dist_n_jobs=-1\n",
    ").fit_predict(embedding)\n",
    "\n",
    "# clusters = SpectralClustering(\n",
    "#     n_clusters=n_clusters, affinity=\"precomputed\", random_state=random_state, n_jobs=-1\n",
    "# ).fit_predict(adj_matrix)\n",
    "\n",
    "# it = girvan_newman(G)\n",
    "# communities = list(itertools.takewhile(lambda c: len(c) <= n_clusters, it))[-1]\n",
    "# clusters_dict = {node: i for i, c in enumerate(communities) for node in c}\n",
    "# clusters = [clusters_dict[node] for node in node_list]\n",
    "\n",
    "counter = Counter(clusters)\n",
    "print(f\"clusters: {np.amax(clusters) + 1}\")\n",
    "print(f\"cluster sizes: {sorted(counter.items(), key=lambda x: x[1], reverse=True)}\")\n",
    "print(f\"noise level: {np.round(counter[-1] / len(clusters), 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "papermill": {
     "duration": 0.009008,
     "end_time": "2020-02-27T10:17:13.627356",
     "exception": false,
     "start_time": "2020-02-27T10:17:13.618348",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "Creating a dataframe from data and results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "papermill": {
     "duration": 13.570333,
     "end_time": "2020-02-27T10:17:27.207698",
     "exception": false,
     "start_time": "2020-02-27T10:17:13.637365",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.random.seed(seed)\n",
    "\n",
    "d = {\"nconst\": node_list, \"cluster\": clusters}\n",
    "df_actor_info = pd.DataFrame(d)\n",
    "df_actor_info[\"degree\"] = df_actor_info[\"nconst\"].apply(G.degree)\n",
    "\n",
    "df_betweenness = pd.DataFrame(betweenness.items(), columns=[\"nconst\", \"betweenness\"])\n",
    "df_actor_info = df_actor_info.merge(df_betweenness, how=\"inner\")\n",
    "\n",
    "df_names_birth_years = pd.read_csv(\n",
    "    \"data/actor_names_birthyear.csv\", sep=\",\", names=[\"nconst\", \"name\", \"birth_year\"]\n",
    ").reset_index()\n",
    "df_names_birth_years = df_names_birth_years.drop([\"index\"], axis=1)\n",
    "df_actor_info = df_actor_info.merge(df_names_birth_years, how=\"left\")\n",
    "\n",
    "df_birth_countries = pd.read_pickle(\"data/birth_countries.pkl\")\n",
    "df_actor_info = df_actor_info.merge(df_birth_countries, how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "papermill": {
     "duration": 0.008006,
     "end_time": "2020-02-27T10:17:27.225714",
     "exception": false,
     "start_time": "2020-02-27T10:17:27.217708",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "Clustering performance evaluation with labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "papermill": {
     "duration": 0.086077,
     "end_time": "2020-02-27T10:17:27.320800",
     "exception": false,
     "start_time": "2020-02-27T10:17:27.234723",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nodes used for eval with labels: 9761\n",
      "AMI: 0.6492026514356981\n",
      "ARI: 0.4251180233543444\n",
      "V-measure: 0.6564659826723629\n",
      "Fowlkes-Mallows: 0.4826404324507997\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(seed)\n",
    "\n",
    "df_eval_wl = df_actor_info[(df_actor_info[\"birth_country\"].notna()) & (df_actor_info[\"cluster\"] != -1)]\n",
    "df_eval_wl = df_eval_wl.reset_index().drop([\"index\"], axis=1)\n",
    "birth_countries = df_eval_wl['birth_country'].values\n",
    "clusters_eval_wl = df_eval_wl['cluster'].values\n",
    "\n",
    "print(f\"nodes used for eval with labels: {len(df_eval_wl)}\")\n",
    "print(f\"AMI: {adjusted_mutual_info_score(birth_countries, clusters_eval_wl)}\")\n",
    "print(f\"ARI: {adjusted_rand_score(birth_countries, clusters_eval_wl)}\")\n",
    "print(f\"V-measure: {v_measure_score(birth_countries, clusters_eval_wl)}\")\n",
    "print(f\"Fowlkes-Mallows: {fowlkes_mallows_score(birth_countries, clusters_eval_wl)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "papermill": {
     "duration": 0.009009,
     "end_time": "2020-02-27T10:17:27.338818",
     "exception": false,
     "start_time": "2020-02-27T10:17:27.329809",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "Clustering performance evaluation without labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "papermill": {
     "duration": 163.400612,
     "end_time": "2020-02-27T10:20:10.751440",
     "exception": false,
     "start_time": "2020-02-27T10:17:27.350828",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nodes used for eval without labels: 12663\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette Coefficient: 0.16879548921974993\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(seed)\n",
    "\n",
    "node_list_eval_wol = [u for i, u in enumerate(node_list) if clusters[i] != -1]\n",
    "clusters_eval_wol = [cluster for cluster in clusters if cluster != -1]\n",
    "\n",
    "G_eval_wol = nx.subgraph(G, node_list_eval_wol)\n",
    "adj_matrix_eval_wol = nx.to_numpy_array(G_eval_wol)\n",
    "dist_matrix_eval_wol = graph_shortest_path(adj_matrix_eval_wol, directed=False, method=\"auto\")\n",
    "\n",
    "print(f\"nodes used for eval without labels: {len(node_list_eval_wol)}\")\n",
    "print(f\"Silhouette Coefficient: {silhouette_score(dist_matrix_eval_wol, clusters_eval_wol, metric='precomputed')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "papermill": {
     "duration": 0.010009,
     "end_time": "2020-02-27T10:20:10.771458",
     "exception": false,
     "start_time": "2020-02-27T10:20:10.761449",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "Printing leaderboard for each cluster when sorted by degree:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "papermill": {
     "duration": 0.145132,
     "end_time": "2020-02-27T10:20:10.925598",
     "exception": false,
     "start_time": "2020-02-27T10:20:10.780466",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "source": [
    "def display_side_by_side(dfs, captions):\n",
    "    output = \"\"\n",
    "    combined = dict(zip(captions, dfs))\n",
    "    for caption, df in combined.items():\n",
    "        output += df.style.set_table_attributes(\"style='display:inline'\").set_caption(caption)._repr_html_()\n",
    "        output += \"\\xa0\\xa0\\xa0\"\n",
    "    display(HTML(output))\n",
    "\n",
    "def print_leaderboards(df):\n",
    "    df_list = []\n",
    "    caption_list = []\n",
    "    for i in range(-1, df[\"cluster\"].max() + 1):\n",
    "        caption_list.append(f\"Cluster idx: {i}\")\n",
    "        cluster_top_actors = df[df[\"cluster\"] == i].reset_index()\n",
    "        cluster_top_actors = cluster_top_actors.drop([\"cluster\", \"index\", \"nconst\"], axis=1)\n",
    "        df_list.append(cluster_top_actors.head(10))\n",
    "    display_side_by_side(df_list, caption_list)    \n",
    "\n",
    "print_leaderboards(df_actor_info.sort_values(by=\"degree\", ascending=False))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "papermill": {
     "duration": 0.015013,
     "end_time": "2020-02-27T10:20:10.955625",
     "exception": false,
     "start_time": "2020-02-27T10:20:10.940612",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "Printing leaderboard for each cluster when sorted by betweenness for nodes:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "papermill": {
     "duration": 0.111101,
     "end_time": "2020-02-27T10:20:11.081740",
     "exception": false,
     "start_time": "2020-02-27T10:20:10.970639",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "source": [
    "print_leaderboards(df_actor_info.sort_values(by=\"betweenness\", ascending=False))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "papermill": {
     "duration": 0.019018,
     "end_time": "2020-02-27T10:20:11.119775",
     "exception": false,
     "start_time": "2020-02-27T10:20:11.100757",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Visualizing the network using Spring and Custom layouts:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "papermill": {
     "duration": 498.596531,
     "end_time": "2020-02-27T10:28:29.735323",
     "exception": false,
     "start_time": "2020-02-27T10:20:11.138792",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "source": [
    "np.random.seed(seed)\n",
    "\n",
    "def draw_network(G, pos, patch_list, node_colors, pdf_name, node_size=1, edge_width=.1, font_size=1):\n",
    "    plt.figure(figsize=(12, 9))\n",
    "    nx.draw_networkx_nodes(G, pos=pos, node_size=node_size, node_color=node_colors)\n",
    "    nx.draw_networkx_edges(G, pos=pos, width=edge_width)\n",
    "    # nx.draw_networkx_labels(G, pos=pos, font_size=font_size)\n",
    "    plt.legend(handles=patch_list, loc=\"center left\", bbox_to_anchor=(1, 0.5), ncol=2, fancybox=True)\n",
    "    plt.savefig(f\"results/{pdf_name + pdf_postfix}.pdf\", bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "palette = plt.cm.Set3.colors \\\n",
    "          + plt.cm.Set2.colors[5:7] \\\n",
    "          + plt.cm.tab10.colors[:-1] \\\n",
    "          + tuple(plt.cm.tab20c.colors[i] for i in [4]) \\\n",
    "          + tuple(plt.cm.tab20b.colors[i] for i in [0, 4, 8, 12, 16]) \\\n",
    "          + plt.cm.tab10.colors[-1:]\n",
    "\n",
    "if np.amax(clusters) + 1 < 30:\n",
    "    node_colors = [palette[cluster] for cluster in clusters]\n",
    "    patch_list = [Patch(color=palette[i], label=i) for i in range(-1, np.amax(clusters) + 1)]\n",
    "else:\n",
    "    print(\"ERROR: cannot visualize more than 29 clusters...\")\n",
    "    node_colors = [palette[-1] for cluster in clusters]\n",
    "    patch_list = [Patch(color=palette[-1], label=-1)]\n",
    "\n",
    "pos_sp = nx.spring_layout(G, seed=seed)\n",
    "pos_su = {node_list[i]: embedding[i] for i in range(len(node_list))}\n",
    "\n",
    "draw_network(G, pos=pos_sp, patch_list=patch_list, node_colors=node_colors, pdf_name=\"graph_sp\")\n",
    "draw_network(G, pos=pos_su, patch_list=patch_list, node_colors=node_colors, pdf_name=\"graph_su\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "papermill": {
     "duration": 0.030028,
     "end_time": "2020-02-27T10:28:29.795378",
     "exception": false,
     "start_time": "2020-02-27T10:28:29.765350",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Visualizing each clusters' mean birth years using custom layout and plotting birth year distributions for each cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.random.seed(seed)\n",
    "\n",
    "df_actor_info[\"birth_year\"] = df_actor_info[\"birth_year\"].replace(\"\\\\N\", np.nan).astype(float)\n",
    "df_actor_info[\"birth_year_mean\"] = df_actor_info.groupby(\"cluster\")[\"birth_year\"].transform(\"mean\")\n",
    "birth_years_means = df_actor_info[\"birth_year_mean\"].values\n",
    "\n",
    "plt.figure(figsize=(15, 9))\n",
    "g = nx.draw_networkx_nodes(\n",
    "    G, pos=pos_su, node_size=1, node_color=birth_years_means, cmap=plt.cm.gist_rainbow,\n",
    "    vmin=np.nanmin(birth_years_means), vmax=np.nanmax(birth_years_means)\n",
    ")\n",
    "nx.draw_networkx_edges(G, pos=pos_su, width=.1)\n",
    "plt.colorbar(g)\n",
    "plt.savefig(f\"results/birth_year_means_su{pdf_postfix}.pdf\", bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "if np.amin(clusters) == -1:\n",
    "    palette = palette[-1:] + palette[:-1]\n",
    "\n",
    "sns.set()\n",
    "plt.figure(figsize=(12, 9))\n",
    "sns.boxplot(x=\"cluster\", y=\"birth_year\", data=df_actor_info, palette=palette)\n",
    "plt.savefig(f\"results/birth_year_distribs{pdf_postfix}.pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "papermill": {
   "duration": 1199.672339,
   "end_time": "2020-02-27T10:29:25.715237",
   "environment_variables": {},
   "exception": null,
   "input_path": "custom_200.ipynb",
   "output_path": "custom_200.ipynb",
   "parameters": {},
   "start_time": "2020-02-27T10:09:26.042898",
   "version": "1.2.1"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}